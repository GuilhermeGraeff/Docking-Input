{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a4479013-e2ea-42e4-b236-c2163fc82e61",
   "metadata": {},
   "outputs": [],
   "source": [
    "import molgrid\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.nn import init\n",
    "import os\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "56a82c06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set some constants\n",
    "batch_size = 50\n",
    "datadir = os.getcwd() +'/../_data'\n",
    "fname = datadir+\"/small.types\"\n",
    "\n",
    "\n",
    "\n",
    "molgrid.set_random_seed(0)\n",
    "torch.manual_seed(0)\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0928a1f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define network architecture\n",
    "class Net(nn.Module):\n",
    "    def __init__(self, dims):\n",
    "        super(Net, self).__init__()\n",
    "        self.pool0 = nn.MaxPool3d(2)\n",
    "        self.conv1 = nn.Conv3d(dims[0], 32, kernel_size=3, padding=1)\n",
    "        self.pool1 = nn.MaxPool3d(2)\n",
    "        self.conv2 = nn.Conv3d(32, 64, kernel_size=3, padding=1)\n",
    "        self.pool2 = nn.MaxPool3d(2)\n",
    "        self.conv3 = nn.Conv3d(64, 128, kernel_size=3, padding=1)\n",
    "\n",
    "        self.last_layer_size = dims[1]//8 * dims[2]//8 * dims[3]//8 * 128\n",
    "        self.fc1 = nn.Linear(self.last_layer_size, 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool0(x)\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = self.pool1(x)\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = self.pool2(x)\n",
    "        x = F.relu(self.conv3(x))\n",
    "        x = x.view(-1, self.last_layer_size)\n",
    "        x = self.fc1(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b1be477e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define weight initialization\n",
    "def weights_init(m):\n",
    "    if isinstance(m, nn.Conv3d) or isinstance(m, nn.Linear):\n",
    "        init.xavier_uniform_(m.weight.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "25108a69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use the libmolgrid ExampleProvider to obtain shuffled, balanced, and stratified batches from a file\n",
    "e = molgrid.ExampleProvider(data_root=datadir+\"/structs\",balanced=True,shuffle=True)\n",
    "e.populate(fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2f99bb11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize libmolgrid GridMaker\n",
    "gmaker = molgrid.GridMaker()\n",
    "dims = gmaker.grid_dimensions(e.num_types())\n",
    "tensor_shape = (batch_size,)+dims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "851d3798",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Net(\n",
       "  (pool0): MaxPool3d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (conv1): Conv3d(28, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "  (pool1): MaxPool3d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (conv2): Conv3d(32, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "  (pool2): MaxPool3d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (conv3): Conv3d(64, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "  (fc1): Linear(in_features=27648, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# initialize Net on GPU\n",
    "# .to('cuda')    vvvvvvv\n",
    "model = Net(dims)\n",
    "model.apply(weights_init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "96421018",
   "metadata": {},
   "outputs": [],
   "source": [
    "# construct optimizer\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8a22173d",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "The NVIDIA driver on your system is too old (found version 11040). Please update your GPU driver by downloading and installing a new version from the URL: http://www.nvidia.com/Download/index.aspx Alternatively, go to: https://pytorch.org to install a PyTorch version that has been compiled with your version of the CUDA driver.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# construct input tensors\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m input_tensor \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mzeros(tensor_shape, dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mfloat32, device\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      3\u001b[0m float_labels \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mzeros(batch_size, dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mfloat32)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/cuda/__init__.py:293\u001b[0m, in \u001b[0;36m_lazy_init\u001b[0;34m()\u001b[0m\n\u001b[1;32m    291\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCUDA_MODULE_LOADING\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m os\u001b[38;5;241m.\u001b[39menviron:\n\u001b[1;32m    292\u001b[0m     os\u001b[38;5;241m.\u001b[39menviron[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCUDA_MODULE_LOADING\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLAZY\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 293\u001b[0m torch\u001b[38;5;241m.\u001b[39m_C\u001b[38;5;241m.\u001b[39m_cuda_init()\n\u001b[1;32m    294\u001b[0m \u001b[38;5;66;03m# Some of the queued calls may reentrantly call _lazy_init();\u001b[39;00m\n\u001b[1;32m    295\u001b[0m \u001b[38;5;66;03m# we need to just return without initializing in that case.\u001b[39;00m\n\u001b[1;32m    296\u001b[0m \u001b[38;5;66;03m# However, we must not let any *other* threads in!\u001b[39;00m\n\u001b[1;32m    297\u001b[0m _tls\u001b[38;5;241m.\u001b[39mis_initializing \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: The NVIDIA driver on your system is too old (found version 11040). Please update your GPU driver by downloading and installing a new version from the URL: http://www.nvidia.com/Download/index.aspx Alternatively, go to: https://pytorch.org to install a PyTorch version that has been compiled with your version of the CUDA driver."
     ]
    }
   ],
   "source": [
    "# construct input tensors\n",
    "input_tensor = torch.zeros(tensor_shape, dtype=torch.float32, device='cuda')\n",
    "float_labels = torch.zeros(batch_size, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60af5277",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train for 500 iterations\n",
    "losses = []\n",
    "for iteration in range(500):\n",
    "    print('up', iteration)\n",
    "    # load data\n",
    "    batch = e.next_batch(batch_size)\n",
    "    # libmolgrid can interoperate directly with Torch tensors, using views over the same memory.\n",
    "    # internally, the libmolgrid GridMaker can use libmolgrid Transforms to apply random rotations and translations for data augmentation\n",
    "    # the user may also use libmolgrid Transforms directly in python\n",
    "    gmaker.forward(batch, input_tensor, 0, random_rotation=False)\n",
    "    batch.extract_label(0, float_labels)\n",
    "    labels = float_labels.long().to('cuda')\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    output = model(input_tensor)\n",
    "    loss = F.cross_entropy(output,labels)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    losses.append(float(loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d06b35b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc05cb3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a1e7a05",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
